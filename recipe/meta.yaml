{% set name = "PtychoNN" %}
{% set version = "0.1.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/mcherukara/PtychoNN/archive/v{{ version }}.tar.gz
  sha256: d8adef0188146c2a8ac06644746330bd2d41936b22a4811b196debece2af82e9

build:
  entry_points:
    - ptychonn = ptychonn.__main__:main
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - pip
    - python >=3.6
    - setuptools >=45
    - setuptools_scm
    - setuptools_scm_git_archive
    - toml
  run:
    - click
    - h5py
    - importlib-metadata
    - importlib-resources
    - matplotlib-base
    - numpy >=1.21,<2
    - python >=3.6
    - pytorch >=1.12,<2
    - scikit-image
    - scipy
    - torchinfo
    - tqdm

test:
  imports:
    - ptychonn
  requires:
    - pip
  commands:
    - pip check
    - ptychonn --help

about:
  home: https://github.com/mcherukara/PtychoNN
  summary: Deep learning of ptychographic imaging
  description: >
    PtychoNN is a two-headed encoder-decoder network that simultaneously predicts sample amplitude and phase from input diffraction data alone. PtychoNN is 100s of times faster than iterative phase retrieval and can work with as little as 25X less data.

    Companion repository to the paper at: https://aip.scitation.org/doi/full/10.1063/5.0013065

  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  dev_url: https://github.com/mcherukara/PtychoNN

extra:
  recipe-maintainers:
    - carterbox
    - mcherukara
    - vbanakha
